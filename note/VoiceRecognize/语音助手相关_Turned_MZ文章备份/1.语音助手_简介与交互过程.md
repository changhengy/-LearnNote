##  语音助手简介

```
	语音助手这个产品的目的，是希望通过语音说话的方式，来实现闲聊陪伴、知识获取、设备控制等需求，对应的就有三种不同的助手类型：闲聊型、问答型、指令型。
​	闲聊型助手用于实现闲聊陪伴的目的，通过AI的技术来与用户进行对话，感知用户情绪，比如微软小冰。
​	问答型助手用于知识获取，通过对话的方式来获取知识，或者解决疑问，比较常见的应用则是各个平台的智能客服，比如京东、淘宝等都有对应的产品。
​	指令型助手用于设备控制，通过对话的方式来控制智能设备，实现某种操作，比较常见的应用有智能音响、IOT设备等，比如，语音控制：“打开空调，然后调成25度”。
​	而集成了这三个能力的语音助手，则是以一个集大成者的贴心助理的形式存在，比如vivo的Jovi语音助手、小米的小爱同学、IPhone的siri。
```

## 语音助手交互过程

**1、首先，来了解一下从用户发出指令到设备端执行，一共经历了哪些流程：**

![](..\..\images\语音助手交互过程.jpg)

​	由上图可以看出，用户发出语音指令，经过语音识别（ASR）服务器转换为文本，然后经过网关进入自然语言理解（NLU）服务器进行语义理解，理解之后经由

对话管理中控（DM）进入技能工具箱得到结构化的控制指令，然后经过语音转文字（TTS）服务将文本信息转为语音信息，进入手机端执行命令并且回复用户。

------

**2、下面我们来简单说下各个模块的作用：**

* 客户端：这里一般是指设备端，比如：手机、音响、智能设备等，用户通过该设备与语音助手进行交互，实现对话、控制设备等操作。 

* 语音识别ASR：ASR实现的功能主要为将语音转换为文字，但其实这里还涉及很多其他技术，一个完整的ASR链路主要包括：语音唤醒、语音输入、静音检测（VAD）、信号处理、特征提取、模型转换等。

* 网关服务：网关服务顾名思义，是一个网络连接到另一个网络的“关口”，承担了一些请求鉴权、服务转发、配置下发、流量控制等能力。

* 语义理解NLU：语义理解的作用为根据文本信息理解句子的含义，这里包含了很多的模块和技术，一般主要分为query预处理和query理解两个部分，在query预处理中一般包含query纠错、问句改写等，在query理解中一般包含分词、依存句法分析、命名实体识别（NER）、场景识别、意图识别、槽位提取、情感分析等。

* 对话管理DM：DM控制着人机对话的状态，他的输入为当前的用户输入（经过语义理解之后的内容），输出为下一步的系统行为和更新后的状态。DM中一般需要负责：BOT的分发、BOT结果排序、对话状态维护（DST），多轮会话一般就是在这里控制的，后续的文章中会详细讲解DM和多轮对话的实现。

* 技能工具箱：这里存放着支持的各个技能，比如：播放音乐（play_music）、查询天气（weather_forecast）、闹钟操作（operate_alarm）等，这里的技能指的是客户端可以执行的内容，是语义内容经过技能封装、知识填充、知识校验等操作后生成的结构化的数据，客户端拿到后可以直接执行。    

————————————————
版权声明：本文为CSDN博主「Turned_MZ」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/mingzheng114/article/details/120071907

