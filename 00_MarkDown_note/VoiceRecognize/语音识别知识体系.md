ASR  :  Automatic Speech Recognition，也被称为自动语音识别  [一文看懂](https://easyai.tech/ai-definition/asr/) [语音交互评价指标](https://zhuanlan.zhihu.com/p/31303097)

​			人->  声音> 采样 > 数据流 > 音素 > 声学模型 >  拼音 >  最概率词组句子 >

NLP : 自然语言**处理**，是Natural Language **Processing**， 简称NLP		 	[自然语言处理（NLP） vs 自然语言理解（NLU）](https://blog.csdn.net/ZLJ925/article/details/79000149)

NLU : 自然语言**理解**，是Natural Language **Understanding**，简称NLU 

NLG :  **自然语言生成（NLG**，Natural Language Generation），简称NLG  [NLU与NLG的区别](https://blog.csdn.net/rensihui/article/details/98532259)

QU ：Query理解（QU，Query Understanding）[全面理解搜索Query](https://zhuanlan.zhihu.com/p/112719984)  [搜索召回](https://zhuanlan.zhihu.com/p/348159133)

IoT设备：物联网（Internet of Things，简称IoT），物联网设备

TTS :  Text To  Speech

VAD ：语音激活检测（VAD, Voice Activation Detection）[三分钟看懂语音激活检测方法](https://blog.ailemon.net/2021/02/18/introduction-to-vad-theory/)

BOT：**因产品概念调整，本文中“BOT”现已更名为“技能**[【提升篇】酒店语音助手实例教程](https://ai.baidu.com/forum/topic/show/892294)

BOT : [BOT泛指虚拟AI助手](https://www.jiemian.com/article/1295757.html)

BERT : Bidirectional Encoder Representation from Transformers，即双向Transformer的Encoder  

* [【NLP】Google BERT模型原理详解](https://zhuanlan.zhihu.com/p/46652512) 
* [NLP必读：十分钟读懂谷歌BERT模型](https://zhuanlan.zhihu.com/p/51413773)
* [Language Model based on BERT](https://octopuscoder.github.io/2019/03/25/Language-Model-based-on-BERT/)

DM :  会话管理(Dialog Management) [会话管理基本概念](https://singlecool.com/2018/04/01/DM/)

DST :  Dialogue State Tracking   [一文看懂任务型对话系统中的状态追踪（DST） ](https://zhuanlan.zhihu.com/p/51476362)

​		对话状态追踪DST：作用是根据领域(domain)/意图(intention) 、槽植对(slot-value pairs)

DSTC： [Dialog System Technology Challenge](https://link.zhihu.com/?target=https%3A//www.microsoft.com/en-us/research/event/dialog-state-tracking-challenge/)

DPL : Dialogue Policy Learning  [一文看懂任务型对话中的对话策略学习（DPL）](https://zhuanlan.zhihu.com/p/52692962)

​		DPL也叫DPO（对话策略优化），跟DST一样，DPL也是对话管理（DM）的一部分，而DM是任务型对话中至关重要的一部分。

​		说个**非严格的对比**：如果把对话系统比作计算机的话，SLU相当于输入，NLG相当于输出设备，而DM相当于CPU（运算器+控制器）。

CNN : Convolutional Neural Networks  卷积神经网络 [一文看懂卷积神经网络](https://easyai.tech/ai-definition/cnn/)     [详解卷积神经网络（CNN）在语音识别中的应用](https://zhuanlan.zhihu.com/p/31606080)

RNN : *Recurrent neural network* 循环神经网络  [一文搞懂RNN（循环神经网络）基础篇](https://zhuanlan.zhihu.com/p/30844905)

FFDNN :  FFDNN（Feed Forward Deep Neural Network） 前馈神经网络

DTW : （Dynamic Time Warping，动态时间规整算法）

PPL : PPL分数，perplexity(困惑度)

ROUGE : 指标的全称是 (Recall-Oriented Understudy for Gisting Evaluation)，主要是基于召回率 (recall) 的

CBOW模型 : (Continuous Bag-Of-Words Model)

* CBOW是已知当前词的上下文，来预测当前词，而Skip-gram则相反，是在已知当前词的情况下，预测其上下文
* [探秘Word2Vec(四)-CBOW模型](https://www.jianshu.com/p/d534570272a6)
* [轻松理解CBOW模型](https://blog.csdn.net/u010665216/article/details/78724856)

Skip-gram模型 : (Continuous Skip-gram Model)

FSM : 有限状态机(finite-state machine)  [什么是有限状态机](https://zhuanlan.zhihu.com/p/100101797)

BER ： 命名实体识别（Named Entity Recognition，简称NER），

* 又称作“专名识别”，是指识别文本中具有特定意义的实体，主要包括人名、地名、	机构名、专有名词等 

* ###### [美团搜索中NER技术的探索与实践](https://tech.meituan.com/2020/07/23/ner-in-meituan-nlp.html)

* ###### [【深度学习与NLP】如何理解LSTM+CRF做命名实体识别？ ](https://zhuanlan.zhihu.com/p/111340463)

CRF ：全称 Conditional Random Fields  条件随机场

LSTM : 长短期记忆（Long short-term memory, LSTM）是一种特殊的RNN.

N-Gram：N 元特征(N-gram 特征),顾名思义,就是由 N 个字或词组成的字符串,单元可以 是字或词。这里N是大于等于1的任意整数。如果N 为2,就叫做二元特征,如果N为 3,就叫做三元特征以此类推。 [自然语言处理中N-Gram模型介绍](https://zhuanlan.zhihu.com/p/32829048)

双向2Gram :  单双向2-gram检测: 统计大规模语料中2gram的频率，检测适合句子中的2-gram小于一定频次即识别为错误。[ **中文纠错技术综述**](https://zhuanlan.zhihu.com/p/357812484)

GBDT： 的全称是 Gradient Boosting Decision Tree，梯度提升决策树。 [GBDT 算法：原理篇](https://zhuanlan.zhihu.com/p/53980138)

HMM：隐马尔可夫模型（Hidden Markov Model，HMM）[一文搞懂HMM（隐马尔可夫模型）](https://www.cnblogs.com/skyme/p/4651331.html)   [如何用简单易懂的例子解释隐马尔可夫模型？](https://www.zhihu.com/question/20962240) 

精确率 ：精确率是针对我们预测结果而言的，它表示的是预测为正的样本中有多少是真正的正样本。

召回率：召回率是针对我们原来的样本而言的，它表示的是样本中的正例有多少被预测正确了。 [如何解释召回率与精确率？]( https://www.zhihu.com/question/19645541)

Seq2Seq ： Sequence-to-sequence 的缩写，就如字面意思，输入一个序列，输出另一个序列。[Encoder-Decoder 和 Seq2Seq]( https://easyai.tech/ai-definition/encoder-decoder-seq2seq/)

UL：Unsupervised learning  无监督学习是机器学习中的一种**训练方式/学习方式** [一文看懂无监督学习](https://easyai.tech/ai-definition/unsupervised-learning/)

SL：Supervised learning  监督学习  [一文看懂监督学习](https://easyai.tech/ai-definition/supervised-learning/)

[Rasa NLU](https://rasa.com/) 是一个开源的、可本地部署并配套有语料标注工具（[rasa-nlu-trainer](https://rasahq.github.io/rasa-nlu-trainer/)）的自然语言理解框架。

WUW : Wake-up Word, *WUW*

VSM： Vector Space Model，向量空间模型。在自然语言处理和信息检索中常用的词袋模型，词袋模型可以看成一种以词为基本单位的向量空间模型

phi ：*Phi*（大写Φ，小写φ，），是第二十一个希腊字母。

theta ：θ，是第八个希腊字母

hspace：多维空间吗？对应多维向量的使用？

DSSM：DSSM是Deep Structured Semantic Model的缩写，即我们通常说的基于深度网络的语义模型，其核心思想是将query和doc映射到到共同维度的语义空间中，通过最大化query和doc语义向量之间的余弦相似度，从而训练得到隐含语义模型，达到检索的目的。DSSM有很广泛的应用，比如：搜索引擎检索，广告相关性，问答系统，机器翻译等。	 [实践DSSM召回模型 ](https://zhuanlan.zhihu.com/p/136253355)  [DSSM论文阅读与总结](https://zhuanlan.zhihu.com/p/53326791)

  
