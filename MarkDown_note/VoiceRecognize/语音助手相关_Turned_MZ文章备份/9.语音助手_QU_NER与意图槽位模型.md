# 九、语音助手——QU——NER与意图槽位模型

这一章，我们一起来看一下语音助手中用到的NER与意图槽位模型，分为以下几部分：

1.  什么是NER？
2.  什么是意图槽位模型？可以有哪些设计形式？
3.  常用的NER与意图槽位模型有哪些？

### 一、什么是NER

​        NER叫做命名实体识别，即提取一句话中的实体，实体可以为时间、地点、人物、音乐名、电视剧名等，比如下面的例子：今天天气不错， 其中包含的实体为：时间：“今天”。

​    	NER模型的本质是一个序列标注任务，即将一段文本中的每个字都打上对应的标签，一般使用的标签为：B(实体开头)，M(实体中间), E(实体结束)，O(非实体), S(单实体，即这个字独立为一个实体)，比如下面的例子：今（B-TIME）天(E-TIME)天(O)气(O)不(O)错(O)，当然这里的“实体”是需要人为定义的，如果只关心天气实体，则上面的例子只需要提取“今天”就可以了，如果还关心天气类型，则天气类型也为一个实体，比如：今（B-TIME）天(E-TIME)会(O)下(B-WEATHER_TYPE)雨(E-WEATHER_TYPE)吗(O)。

### 二、什么是意图槽位模型

​        在语音助手中，需要理解一句话中用户的意图，并且提取关心的关键词（即槽位），比如：“今天会下雨吗”，这句话中意图为：天气查询； 槽位为：时间：”今天“；天气类型：”下雨“。根据意图和槽位信息，助手需要去查询当前的天气会不会下雨，然后回复用户。

​    	对于这个任务，可以有两种设计方式：

​		1、将任务利用两个模型分别来做，即分类+NER，利用分类来识别query意图，利用NER来提取槽位。

​		2、将任务当做两个任务，但是利用一个模型来做，即联合学习，同时学习query中的意图和槽位信息。

我们一般推荐使用方法2来做，理由如下：

* 对于一个query，其意图和槽位信息是互相影响的，即意图信息会影响槽位的标注，槽位信息又会反过来影响意图的识别。并且真正使用时意图和槽位也是配套使用的，如果两个不对应，可能会导致技能执行错误。举个例子：query1：播放歌曲外婆家。 query2：导航去外婆家吃饭。 这里query1意图为播放音乐，此时”外婆家“为歌曲名，query2意图为导航，此时”外婆家“为地点。
* 如果拆分为两个模型，则最终效果为两个模型结合的效果，如果一个模型准确率为90%，另外一个为80%，则最终效果为72%，根据实验对比，联合学习方案虽然在分类和NER两个任务和可能比单纯的两个模型效果略差，但是综合的效果却是强于两个模型拆分的。

### 三、常用的模型设计方案

​        首先，确认下模型的输入输出，在预测阶段，输入为一句query，输出为意图+NER结果。在训练阶段，属入为一句query，以及意图信息和NER标注信息，比如：query：”今天天气不错“。intent:"weather_forecast"，slot：”time:[(今天，0，1)]，weather_type:[(天气，2，3)]“，这里slot数据的形式解释一下：实体类型:[(实体，实体开头位置，实体结束位置)]。在实际训练时，会将slot的数据格式化为：B-TIME, E-TIME,B-WEATHER_TYPE,E-WEATHER_TYPE,O,O

​    	然后来看下模型的设计，对于单纯的NER模型，可以使用的模型方案为：BILSTM-CRF，即双向lstm+CRF，另外一种方案为：transformer（encoder部分）+CRF，利用CRF（条件随机场）可以大大提升NER的实体的准确率，这在NER中已经是确定的模块了（当然，如果你用BERT，CRF就没那么必要了，但是BERT太大了，其速度和部署成本一般很难满足线上要求），这两种方案都已经是很成熟的方案了，这里不再赘述，其效果上也差不多。

​    	接下来看下意图槽位联合学习的模型设计，有两种设计方案：**1、transformer（encoder部分）+CRF。2、SF-ID**。下面来看下。

#### 方案1：transformer（encoder部分）+CRF：

![](..\..\\images\ransformer(encoder部分)+CRF.png)

​	    如上图，将query编码为embedding后，通过一层transformer-encoder编码，这部分作为联合任务中的共享层，下面针对意图识别和槽位提取做两个解码层，其中intent部分使用一层transformer-encoder+FC来做分类，slot部分利用transformer-encoder+FC+CRF来做NER任务。

​	    可能有同学会问，这里做slot任务的解码部分为什么不可以用transformer-decoder部分呢？做NER用不到transformer的解码器，只需要用编码器得到每个词的上下文表示就行了，transformer-decoder部分一般用来做生成任务，利用生成序列和输入序列做attention，生成序列自身做self-attention，得到下一个词输出。当然，这里做NER也并非不可以用transformer-decoder，只是没有必要，这个任务相对来说比较简单，利用CRF效果就已经很好了。

#### 方案2：SF-ID：

​    该方案整体架构如下图：

![](..\..\\images\SF-ID.png)

对应的论文信息如下：

* A Novel Bi-directional Interrelated Model for Joint Intent Detection and Slot Filling
* 文章来源：ACL2019
* 下载地址：A Novel Bi-directional Interrelated Model for Joint Intent Detection and Slot Filling
* 论文源码(tf)：https://github.com/ZephyrChenzf

这个方法提出了一个双向相关的模型来完成SLU中的slot filling和intent detection任务，模型可以使两个任务之间相互提供有效信息来提升性能（iteration mechanism），详细的解析可以看这篇文章：SLU之slot filling and intent detection（2）-阅读笔记 - 知乎 ， 这里就不展开了。

### 四、一些优化方案

#### 1、模型效果提升：

​	 	针对模型效果提升，可以使用蒸馏的方法，即利用bert蒸馏transformer。

#### 2、未登录词识别效果问题：

​    	问题描述：对于一些训练集中没有出现过的词，NER可能会识别错误，尤其是一些新词频繁出现且没有明显特征的场景，比如音乐，音乐名称更新频繁且没有固定特征，所以一些未出现的新歌模型识别效果可能会比较差。

​    	解决方案：对于这个问题，可以通过slot_dict的方法来解决，其思想为：将新词放到一个词典中，对新词词典训练一个word_embedding，每次使用模型进行NER识别时，通过查词典，对于查到的词在原始的embedding层加上查到的word_embedding增强对应位置的权重来提升其特征。这种方案可以通过只更新新词词典的word_embedding，而不必重新训练整个模型来提升新词的识别效果。

————————————————
版权声明：本文为CSDN博主「Turned_MZ」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/mingzheng114/article/details/120692678